# LLM Configuration Template
# Copy this file to llm.env and fill in your actual credentials
# llm.env is in .gitignore and will NOT be committed to Git

# ============================================================
# LLM PROVIDER CONFIGURATION
# ============================================================
# Choose ONE of the following options and uncomment it

# Option 1: Local Ollama (Recommended for development)
LLM_TYPE=LOCAL_OLLAMA
OLLAMA_SERVER_URL=http://host.docker.internal:11434
OLLAMA_MODEL_NAME=mistral

# Option 2: IBM Watsonx
# LLM_TYPE=WATSONX
# WATSONX_APIKEY=<your_watsonx_api_key>
# WATSONX_PROJECT_ID=<your_project_id>
# WATSONX_URL=https://us-south.ml.cloud.ibm.com
# WATSONX_MODEL_NAME=mistralai/mistral-7b-instruct-v0-2

# Option 3: OpenAI
# LLM_TYPE=OPENAI
# OPENAI_API_KEY=<your_openai_api_key>
# OPENAI_MODEL_NAME=gpt-4
# OPENAI_TEMPERATURE=0.0
# OPENAI_MAX_TOKENS=4000

# Option 4: IBM BAM
# LLM_TYPE=BAM
# WATSONX_APIKEY=<your_bam_api_key>
# WATSONX_URL=https://bam-api.res.ibm.com
# WATSONX_MODEL_NAME=mistralai/mistral-7b-instruct-v0-2

# ============================================================
# AWS CONFIGURATION (Required for Textract and S3)
# ============================================================
AWS_ACCESS_KEY_ID=<your_aws_access_key_id>
AWS_SECRET_ACCESS_KEY=<your_aws_secret_access_key>
AWS_DEFAULT_REGION=us-east-1

# S3 Bucket for policy documents and generated rules
S3_BUCKET_NAME=<your_s3_bucket_name>

# ============================================================
# DROOLS CONFIGURATION (Default values - usually don't need to change)
# ============================================================
DROOLS_SERVER_URL=http://drools:8080/kie-server/services/rest/server
DROOLS_USERNAME=kieserver
DROOLS_PASSWORD=kieserver1!

# ============================================================
# IBM ODM CONFIGURATION (Optional - only if using ODM)
# ============================================================
# ODM_SERVER_URL=http://odm:9060/DecisionService/rest
# ODM_USERNAME=odmAdmin
# ODM_PASSWORD=odmAdmin

# ============================================================
# IBM ADS CONFIGURATION (Optional - only if using ADS)
# ============================================================
# ADS_SERVER_URL=https://<your-ads-server>
# ADS_USER_ID=<your_user_id>
# ADS_ZEN_APIKEY=<your_api_key>

# ============================================================
# NOTES
# ============================================================
# 1. Replace all <placeholders> with actual values
# 2. Keep this file secure - it contains credentials
# 3. Never commit llm.env to Git (it's in .gitignore)
# 4. Share llm.env with teammates securely (encrypted email, password manager, etc.)
